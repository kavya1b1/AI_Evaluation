ğŸ¤– AI Proposal Evaluation System

An end-to-end AI-powered decision support system that automatically evaluates R&D / research proposals using Machine Learning, Explainable AI (XAI), Uncertainty Estimation, and Generative AI, and generates a professional evaluation report.

ğŸ“Œ Problem Statement

Manual evaluation of research and R&D proposals is:

â³ Time-consuming

âš–ï¸ Subjective and inconsistent

âŒ Lacking transparency

ğŸ“„ Poorly documented

Funding agencies, academic institutions, and innovation boards need a scalable, explainable, and objective system that can:

Assess proposal quality

Justify decisions transparently

Estimate confidence and risk

Generate professional evaluation reports

ğŸ’¡ Our Solution

We built an AI Proposal Evaluation System that:

âœ”ï¸ Analyzes proposal PDFs
âœ”ï¸ Scores novelty, feasibility, and financial alignment
âœ”ï¸ Uses ML ensembles with uncertainty estimation
âœ”ï¸ Explains decisions using Explainable AI & SHAP
âœ”ï¸ Generates AI-written evaluation narratives
âœ”ï¸ Produces downloadable PDF reports
âœ”ï¸ Provides an interactive, modern dashboard

ğŸ§  System Architecture
User (Browser)
     â”‚
     â–¼
Streamlit Frontend (dashboard.py)
     â”‚
     â–¼
FastAPI Backend (proposal_routes.py)
     â”‚
     â”œâ”€â”€ Document Parsing (PDF â†’ Text)
     â”œâ”€â”€ Novelty Analysis
     â”œâ”€â”€ Financial Feasibility Check (Budget)
     â”œâ”€â”€ ML Evaluation + Uncertainty
     â”œâ”€â”€ Explainable AI (Feature Importance + SHAP)
     â”œâ”€â”€ Generative AI Narrative
     â”œâ”€â”€ PDF Report Generation
     â”‚
     â–¼
SQLite Database (Evaluation History)

ğŸ§© Key Features
ğŸ“„ Proposal Upload & Parsing

Accepts proposal PDFs

Extracts and processes text automatically

ğŸ“Š ML-Based Evaluation

Ensemble-based scoring model

Outputs final score (0â€“100)

ğŸ’° Budget Analysis (Why Budget Matters)

Budget is not optional noise â€” it directly impacts feasibility.

It is used to:

Check alignment with funding norms

Penalize unrealistic budgets

Balance innovation vs practicality

ğŸ“Œ A great idea with an unrealistic budget is risky â€” the model captures this trade-off.

ğŸ“ˆ Confidence & Uncertainty Estimation

Produces a confidence band (lower, mean, upper)

Shows how reliable the prediction is

Helps decision-makers understand risk

ğŸ§  Explainable AI (XAI)

Feature importance for transparency

SHAP explanations for local predictions

Answers: â€œWhy did the model give this score?â€

ğŸ¤– Generative AI Narrative

Automatically generates a human-readable evaluation

Explains strengths, weaknesses, and recommendations

Makes reports reviewer-ready

ğŸ“„ Automated PDF Report

Each evaluation produces a professional PDF containing:

Scores

Decision

Explainable AI insights

Confidence & risk

AI-generated narrative

ğŸ•’ Evaluation History

Stores past evaluations

Displays timeline with scores & decisions

ğŸ› ï¸ Tech Stack
Frontend

Streamlit

Plotly (interactive charts)

Custom CSS (glassmorphism UI)

Backend

FastAPI

SQLAlchemy

SQLite

Machine Learning

Scikit-learn

Ensemble scoring logic

Confidence estimation via sampling

Explainable AI

Feature Importance

SHAP

Generative AI

LLM-based narrative generation (via API)

Reporting

ReportLab (PDF generation)
